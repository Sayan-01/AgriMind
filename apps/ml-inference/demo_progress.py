#!/usr/bin/env python3
"""
Demo script to showcase the enhanced download progress features.
This simulates the download process without actually downloading files.
"""

import time
import random
from pathlib import Path
import sys

# Add src to path for imports
sys.path.append('src')

from progress_utils import ProgressBar, MultiStageProgress, format_bytes, format_time, show_system_info

def simulate_download(dataset_name: str, size_mb: int, duration_seconds: int):
    """Simulate downloading a dataset with progress tracking."""
    
    print(f"\nüì¶ Simulating download: {dataset_name}")
    print(f"üìè Size: {size_mb} MB")
    print(f"‚è±Ô∏è  Expected duration: {duration_seconds}s")
    
    # Create progress bar
    progress = ProgressBar(size_mb, f"üì• Downloading {dataset_name}")
    
    start_time = time.time()
    downloaded = 0
    
    # Simulate variable download speed
    while downloaded < size_mb:
        # Simulate network variations
        chunk_size = random.randint(1, 10)  # Variable download speed
        chunk_size = min(chunk_size, size_mb - downloaded)
        
        downloaded += chunk_size
        progress.update(chunk_size)
        
        # Sleep to simulate time
        time.sleep(duration_seconds / size_mb * chunk_size * random.uniform(0.8, 1.2))
    
    elapsed_time = time.time() - start_time
    progress.finish(f"{dataset_name} downloaded in {elapsed_time:.1f}s")
    
    return True

def demo_enhanced_download_progress():
    """Demonstrate the enhanced download progress system."""
    
    print("üå± AgriMind Enhanced Download Progress Demo")
    print("=" * 60)
    
    # Show system info
    show_system_info()
    
    # Dataset information (simulated)
    datasets = [
        {"name": "PlantVillage", "size_mb": 870, "duration": 8},
        {"name": "PlantDoc", "size_mb": 416, "duration": 4},
        {"name": "Bangladeshi Crops", "size_mb": 125, "duration": 2},
        {"name": "Rice Leaf Diseases", "size_mb": 48, "duration": 1}
    ]
    
    # Calculate totals
    total_size = sum(d["size_mb"] for d in datasets)
    total_duration = sum(d["duration"] for d in datasets)
    
    print(f"üìä DOWNLOAD PLAN")
    print("-" * 30)
    print(f"üì¶ Total datasets: {len(datasets)}")
    print(f"üíæ Total size: {format_bytes(total_size * 1024 * 1024)}")
    print(f"‚è±Ô∏è  Estimated time: {format_time(total_duration)}")
    
    input("\nPress Enter to start simulation...")
    
    # Create multi-stage progress tracker
    stages = [
        "Checking Kaggle credentials",
        "Fetching dataset information", 
        "Downloading datasets",
        "Extracting and validating"
    ]
    
    tracker = MultiStageProgress(stages)
    
    # Stage 1: Check credentials
    tracker.start_stage(0)
    time.sleep(0.5)
    tracker.update_stage_progress(1, "Kaggle API credentials verified")
    time.sleep(0.5)
    tracker.complete_stage()
    
    # Stage 2: Fetch info
    tracker.start_stage(1, len(datasets))
    for i, dataset in enumerate(datasets):
        time.sleep(0.3)
        tracker.update_stage_progress(1, f"Fetched info for {dataset['name']}")
    tracker.complete_stage()
    
    # Stage 3: Download datasets
    tracker.start_stage(2, len(datasets))
    overall_progress = ProgressBar(len(datasets), "üì• Overall Download Progress")
    
    for i, dataset in enumerate(datasets):
        success = simulate_download(
            dataset["name"], 
            dataset["size_mb"], 
            dataset["duration"]
        )
        
        if success:
            overall_progress.update(1, f"Completed {dataset['name']}")
            tracker.update_stage_progress(1, f"Downloaded {dataset['name']} ({format_bytes(dataset['size_mb'] * 1024 * 1024)})")
    
    overall_progress.finish("All datasets downloaded!")
    tracker.complete_stage()
    
    # Stage 4: Extract and validate
    tracker.start_stage(3, len(datasets))
    extraction_progress = ProgressBar(len(datasets), "üìÇ Extracting datasets")
    
    for i, dataset in enumerate(datasets):
        time.sleep(0.5)  # Simulate extraction time
        extraction_progress.update(1, f"Extracted {dataset['name']}")
        tracker.update_stage_progress(1, f"Validated {dataset['name']}")
    
    extraction_progress.finish("All datasets extracted and validated!")
    tracker.complete_stage()
    
    # Complete the process
    tracker.complete()
    
    print(f"\nüéä DEMO COMPLETE!")
    print(f"üí° This demonstrates the enhanced progress tracking that will be used")
    print(f"   when downloading real datasets with Kaggle API")
    
    print(f"\nüìã FEATURES DEMONSTRATED:")
    print(f"   ‚úÖ Real-time download progress with size tracking")
    print(f"   ‚úÖ Multi-stage process visualization")
    print(f"   ‚úÖ ETA calculations and speed monitoring")
    print(f"   ‚úÖ System information display")
    print(f"   ‚úÖ Error handling and recovery options")
    
    print(f"\nüöÄ To run actual downloads:")
    print(f"   python scripts/download_datasets.py")

if __name__ == "__main__":
    try:
        demo_enhanced_download_progress()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Demo interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Demo error: {e}")
